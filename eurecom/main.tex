\define\secpar{\lambda}
\define\secparam{1^\lambda}
\define\adversary{\mathcal{A}}
\define\negl{\rm{negl(\secpar)}}
\define\NN{\mathbb{N}}
\define\sk{\rm{sk}}
\define\pk{\rm{pk}}
\define\msg{\rm{m}}
\define\cipher{\rm{c}}
\define\cMSG{\mathcal{M}}
\define\sample{\leftarrow}
\define\Sigeufgame{\rm{G}^\rm{euf}}
\define\cQuery{\mathcal{Q}}
\define\signature{s}
\define\kgen{\rm{KGen}}
\define\sign{\rm{Sign}}
\define\ver{\rm{Ver}}

\define\gen{\rm{Gen}}
\define\prover{\rm{P}}
\define\verifier{\rm{V}}

\define\mpk{\rm{mpk}}
\define\msk{\rm{msk}}
\define\ek{\rm{ek}}
\define\dk{\rm{dk}}
\define\kpol{\rm{kpol}}
\define\sattr{\sigma}
\define\rattr{\rho}
\define\saccess{\mathbb{S}}
\define\raccess{\mathbb{R}}
\define\skgen{\rm{SKGen}}
\define\rkgen{\rm{RKGen}}
\define\polgen{\rm{PolGen}}
\define\enc{\rm{Enc}}
\define\dec{\rm{Dec}}

\define\?{\overset{?}{=}}



\environment slides

\definemode[pke-full][yes]

\starttext

\setvariables[metadata][
    title={Matchmaking Encryption. \\ A quick overview},
    author={Luigi Russo},
    date={\currentdate}
]

\startslide[title={Road Map}]
\startitemize[broad]
\item Introduction
\item Matchmaking Encryption
\item Showcase Application
\item Enhanced Security \important{*}
\item Beyond ME
\stopitemize
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Introduction}
]

\startmode[pke-full]
\startslide[title={Public Key Encryption}]
\startitemize[broad]
%\item Alice wants to send a message to Bob
\item Bob generates a pair of keys $(\pk, \sk)$ and \underbar{publishes} $\pk$
\item Alice uses $\pk$ to encrypt the message
\item Bob uses $\sk$ to decrypt
\stopitemize
%\stopslide
%\stopmode

%\startslide[title={PKE: an example}]
\placefigure[none]{}{\externalfigure[images/pke][maxwidth=0.7\textwidth]}
\stopslide

\startslide[title={Identity-Based Encryption}]
IBE is a type of PKE, proposed by Shamir in 1984, in which:
\startitemize[1]
\item public keys are identities (email address, phone numbers, etc.)
\item a trusted party distributes the decryption keys to the receivers
\stopitemize
\blank[3*big]
The first construction of IBE was by Boneh and Franklin in 2001.
\stopslide

\startslide[title={Attribute-Based Encryption}]
ABE is a type of PKE, proposed by Sahai and Waters in 2004, in which:
\startitemize[1, broad]
\item secret keys and ciphertext depend upon user attributes
\item the decryption of a ciphertext is possible only if the set of attributes of the user key matches the attributes of the ciphertext
\item the same ciphertext may be potentially decrypted by different users
\item a trusted party distributes the keys
\stopitemize
\stopslide

\startslide[title={Types of ABE}]
{\bf Ciphertext-Policy ABE}
\startitemize[broad]
\item the decryption key is associated with receiver's attributes
\item the policy is embedded in the ciphertext
\stopitemize
\blank[2*big]
{\bf Key-Policy ABE}
\startitemize[broad]
\item the decryption key is associated with a policy
\item the ciphertext is annotated with attribute sets
\stopitemize
\stopslide

\startslide[title={CP-ABE: an example}]
\placefigure[none]{}{\externalfigure[images/cp_abe][maxwidth=0.9\textwidth]}
\stopslide

\startslide[title={KP-ABE: an example}]
\placefigure[none]{}{\externalfigure[images/kp_abe][maxwidth=0.65\textwidth]}
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Matchmaking Encryption}
]

\startslide[title={Matchmaking Encryption}]
\startitemize[1, broad]
\item The sender $\sattr$ can specify a policy $\raccess$ for the receiver
\item The receiver $\rattr$ can specify a policy $\saccess$ for the sender
\item The policies are represented as circuits $\mathbb{C}:\{0, 1\}^* \to \{0, 1\}$
\item If both the policies are matched, i.e. $\saccess(\sattr) = \raccess(\rattr) = 1$, then the decryption is successful. Otherwise \underbar{nothing} is leaked.
\item A trusted party stores the secrets
\stopitemize
\stopslide

\startslide[title={ME: an example}]
\placefigure[none]{}{\externalfigure[images/me][maxwidth=0.9\textwidth]}
\stopslide

\startslide[title={ME vs ABE}]
{\bf ME $\Rightarrow$ CP-ABE}
\startitemize
\item "Ignore" the policy $\saccess$ set by the receiver ($\saccess$ is a tautology)
\item Match condition becomes: $\raccess(\rattr) \land 1 \? 1$
\stopitemize
\blank[2*big]
{\bf ME $\Rightarrow$ KP-ABE}
\startitemize
\item "Ignore" the policy $\raccess$ set by the sender ($\raccess$ is a tautology)
\item Choose sender attributes on the fly
\item Match condition becomes: $1 \land \saccess(\sattr) \? 1$
\stopitemize
\stopslide

\startslide[title={ME from ABE?}]
It could be possible to build ME as a 2-layers ABE.

    {\bf The sender}
\startitemize[packed]
\item encrypts the message with a KP-ABE scheme (1st layer)
\item then, encrypts this ciphertext using a CP-ABE (2nd layer)
\stopitemize
{\bf The receiver}
\startitemize[packed]
\item decrypts the outer layer with a key associated with his attributes (CP-ABE)
\item then, decrypts using a key associated with a policy (KP-ABE)
\stopitemize

\important{The receiver knows which policy (if any) does not match.}
\stopslide

\startslide[title={Functional Encryption}]
A type of PKE where:
\startitemize[packed]
\item secret keys are associated with some function $F$
\item we can \underbar{learn a function} of what the ciphertext is encrypting
\stopitemize
\startformula
\dec(\sk_F, \enc(\pk, x)) = \important{F(}x\important{)}
\stopformula
\blank[2*big]
{\bf Randomized FE (rFE)}
\startitemize[packed]
\item $F$ accepts some fresh randomness
\stopitemize
\startformula
\dec(\sk_F, \enc(\pk, x)) = F(x; \important{r})
\stopformula
\stopslide

\startslide[title={ME: Construction}]
ME uses a combination of rFe and FE schemes.

The inner layer is computed with FE (needs \important{$\sk_\saccess$} to decrypt).
\startformula
F_\saccess(\sattr, x) = \cases{x, \; if \; \saccess(\sattr) = 1 \cr
    \bot, \; else \cr}
\stopformula

The outer layer is computed with rFE (needs \important{$\sk_\rattr$} to decrypt).
\startformula
F_\rattr(\sattr, \raccess, x; r) = \cases{\enc_{FE}(\sattr, \msg), \; if \; \raccess(\rattr) = 1 \cr \enc_{FE}(\bot, \bot), \; else}
\stopformula

To encrypt run $\enc_{rFE}(\sattr, \raccess, x))$

To decrypt run $ \dec_{FE}(\sk_\saccess, \dec_{rFE}(\sk_\rattr, c))$
\stopslide

\startslide[title={Add Authenticity}]
\startitemize
\item The previous construction lacks authenticity: anyone can encrypt using arbitrary sender attributes $\sattr^*$
\item To solve this issue, the authority generates secret encryption keys $\ek_\sattr$, i.e., a signature on $\sattr$.
\item The sender proves in zero-knowledge that he knows a valid signature of the attributes $\sattr$ used to produce the ciphertext, and attaches this proof $\pi$ to the ciphertext. The receiver verifies $\pi$ during the decryption.
\stopitemize
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Applications}
]

\startslide[title={Applications}]
\startitemize[1, broad]
\item Social matchmaking
\item Encrypting bids
\item Encrypting votes
\item Liability exemption
\item \dots
\stopitemize
\stopslide

\startslide[title={An Anonymous Bulletin Board}]
\startitemize
\item A user that wants to post a message to the bulletin board IB-ME encrypts a message, specifying the policy $rcv$ for the intended receiver
\item Uploads the ciphertext to the web server through the Tor network
\item The webserver makes these ciphertexts publicly available through a REST API
\item A receiver can download all the ciphertexts and try to decrypt each of them, using his decryption keys
\stopitemize
\stopslide

\startslide[title={Distribution of the Keys}]
Need of a service that automatically converts email addresses (or phone numbers) into keys.
\startitemize
\item out-of-band channel, external to TOR, but \underbar{trusted}
\item another TOR hidden service
\item integrated with an existing HSDir (already assumed to be trusted because downloaded from legitimate servers)
\item \dots
\stopitemize
\stopslide

\startslide[title={Space costs of IB-ME elements}]
\placetable
[none]
{}
{\starttable[|c|c|c|]
    \HL
    \NC \bf Element \NC \bf Cost \NC \bf Bitsize \NC\SR
    \HL
    \NC Encryption Key
    \NC $|\cal{G}|$
    \NC 512
    \NC\LR
    \NC Decryption Key
    \NC $3|\cal{G}|$
    \NC 1536
    \NC\LR
    \NC Message
    \NC $|\cal{G}_T|$
    \NC 1024
    \NC\LR
    \NC Ciphertext
    \NC $2|\cal{G}| + padding$
    \NC 2129
    \NC\LR
    \HL
    \stoptable}
Implementation: Charm’s curve SS512
\stopslide

\startslide[title={Security Guarantees}]
{\bf ME Privacy}
\startitemize
\item Messages are disclosed if and only if a match occurs
\stopitemize
\blank[2*big]
{\bf Plus}
\startitemize
\item IP addresses remain secret
\item The connection between the client and the server remains hidden
\stopitemize
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={CCA Security}
]

\startslide[title={Chosen-Ciphertext Attacks}]
\startitemize
\item The attacker can gather information by obtaining the decryptions of chosen ciphertexts.
\item From these pieces of information can attempt to break the security (e.g., recover the secret key)
\item Fundamental in many practical situations
\stopitemize
\blank[2*big]
{\important [Ateniese et al. 2019] did not consider CCA.}
\stopslide

\startslide[title={Thesis Contributions}]
\startitemize[n]
\item Extend the security definitions to handle chosen-ciphertext attacks
\startitemize[1, packed]
\item CCA Privacy
\item CCA Authenticity
\stopitemize
\item Provide blackbox constructions from CPA to CCA to obtain:
\startitemize[1, packed]
\item Privacy only
\item Authenticity only
\item Privacy and Authenticity
\stopitemize
\stopitemize
{\important We have made this for both {\underbar general} and {\underbar arranged} settings.}
\stopslide

\startslide[title={Privacy}]
{\bf CPA setting}
\startitemize[packed, broad]
\item captures secrecy of sender's inputs in presence of malicious receivers.
\item in case of mismatch, the reason why the match did not occur is not revealed.
\stopitemize

{\bf CCA extension}
\startitemize[packed, broad]
\item the adversary may now additionally have access to a decryption
oracle that answers decryption queries
\item enforce privacy even in the presence of attackers who can obtain the decryption of possibly mauled ciphertexts.
\stopitemize
\stopslide

\startslide[title={Authenticity}]
{\bf CPA setting}
\startitemize[packed, broad]
\item captures security against malicious senders
\item no adversary can spoof the sender identity
\stopitemize

{\bf CCA extension}
\startitemize[packed, broad]
\item the attacker is also given access to an encryption oracle
\item captures authenticity in the presence of attackers that try to generate valid ciphertexts by mauling previously obtained ciphertexts
\stopitemize
\stopslide

\startslide[title={CCA Transformation Lattice}]
\startitemize[packed]
\item P/p: CCA/CPA Privacy
\item A/a: CCA/CPA Authenticity
\item 1-6: lemmas
\stopitemize
\startalignment[middle]
\dontleavehmode
\externalfigure[images/constr][horizontal]
\stopalignment
\stopslide

\startslide[title={Digital Signatures}]
A digital signature $\Pi = (\kgen, \sign, \ver)$ is a scheme for verifying the authenticity of digital messages.

The recipient knows that the message:
\startitemize[packed,broad]
\item was created by a known sender ({\bf authentication})
\item was not altered in transit ({\bf integrity})
\stopitemize
\stopslide

\startslide[title={Non-Interactive Zero-Knowledge}]
A NIZK proof system $\Pi = (\gen, \prover, \verifier)$ is a method by which the prover $\prover$ can prove to the verifier $\verifier$ that he knows a value $x$:
\startitemize
\item without interaction ({\bf non-interactive})
\item without conveying any information apart from the fact that he knows the value $x$ ({\bf zero-knowledge})
\stopitemize
If $\prover$ does not know $x$ cannot produce a proof ({\bf soundness})
\stopslide

\startslide[title={Showcase: CCA Direct Transformation}]
\externalfigure[images/cca_constr][maxwidth=\textwidth]
\stopslide

\startslide[title={Sketch Proof}]
\startitemize[1, broad]
\item CCA-authenticity reduced to EUF-CMA of Digital Signatures.
\item CCA-privacy reduced to CPA-Privacy
\stopitemize
\stopslide

\startslide[title={CCA Privacy Reduction 1/2}]
The decryption oracle is simulated thanks to $f$-extractability of the NIZK.
\bigskip
\externalfigure[images/cca_reduction/4_full][maxwidth=0.9\textwidth]
\bigskip
* f-extractability: we can extract information from NIZK proofs if we know an extraction trapdoor $\xi$.
\stopslide

\startslide[title={CCA Privacy Reduction 2/2}]
Here we can see how the last step of the reduction works.
We attach a simulated proof $\pi$ for $c'_b$ and let the attacker work on it
\bigskip
\externalfigure[images/cca_reduction/5_full][maxwidth=\textwidth]
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Beyond ME}
]

\startslide[title={Open problems}]
\startitemize[1, broad]
\item ME from standard assumptions
\item Efficient IB-ME constructions
\item Mitigating Key Escrow
\item Blackbox Constructions from ABE
\stopitemize
\stopslide

\startslide[title={Key Escrow}]
\startitemize[broad]
\item All users’ private keys are issued by an unconditionally trusted authority
\item Such an authority owns the master secret key of the system, and can decrypt all ciphertexts encrypted to any user
\item Potentially this is the target for some attacker which can obtain private keys and redistribute them for malicious use
\stopitemize
\blank[2*big]
{\important Can we reduce the trust in the authority in an ME system?}
\stopslide

\startslide[title={Registration-Based ME}]
\startitemize[broad]
\item Substitute the trusted authority with a weaker entity called key curator who has no knowledge of any secret key
\item Each party generates its own secret key and publicly register its identity and the corresponding public key to the key curator
\item RBE schemes can be constructed from standard assumptions
\stopitemize
\stopslide

\startslide
\blank[7*big]
\startalignment[middle]
\tfd Thanks!
\stopalignment
\stopslide

\startslide[title={Some extras}]
\startitemize
\item ME vs A-ME
\item ME Game-Based Definitions
\item Dual Policy ABE
\item Some formal definitions of cryptographic primitives
\item CCA-Privacy Proof
\stopitemize
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Arranged ME}
]

\startslide[title={Many types of ME}]
\startitemize[1, broad]
\item {\bf General}
\startitemize[packed]
\item One private key per user
\item One key for each policy
\stopitemize
\item {\bf Arranged}
\startitemize[packed]
\item A single key is associated with both attributes and policy
\stopitemize
\item {\bf Identity-Based}
\startitemize[packed]
\item Attributes are simply identities
\stopitemize
\stopitemize
\stopslide

\startslide[title={General Setting}]
\startitemize[1,broad]
\item Key Generation, managed by the trusted party:
\startitemize[packed, broad]
\item $\skgen(\msk, \sattr)$
\item $\rkgen(\msk, \rattr)$
\item $\polgen(\msk, \saccess)$
\stopitemize
\item Encryption. $\enc(\ek_\sattr, \raccess, \msg)$
\item Decryption. $\dec(\dk_\rattr, \dk_\saccess, \cipher)$
\item Correctness. If $\saccess(\sattr) = \raccess(\rattr) = 1:$
\startformula
Pr[\dec(\dk_\rattr, \dk_\saccess, \enc(\ek_\sattr, \raccess, \msg)) = 1] \ge 1 - \negl
\stopformula
\stopitemize
\stopslide

\startslide[title={Arranged Matchmaking}]
\startitemize[1,broad]
\item Key Generation, managed by the trusted party:
\startitemize[packed, broad]
\item $\skgen(\msk, \sattr)$
\item $\rkgen(\msk, \rattr, \important{\saccess})$
\item $\overstrike{\polgen(\msk, \saccess)}$
\stopitemize
\item Encryption: $\enc(\ek_\sattr, \raccess, \msg)$
\item Decryption: $\dec(\dk_{\rattr, \important\saccess}, \cipher)$
\item Correctness. If $\saccess(\sattr) = \raccess(\rattr) = 1:$
\startformula
Pr[\dec(\dk_{\rattr, \saccess}, \enc(\ek_\sattr, \raccess, \msg)) = 1] \ge 1 - \negl
\stopformula
\stopitemize
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={ME: Game-Based Definitions}
]

\startslide[title={CCA Privacy Game}]
Captures secrecy of sender's inputs.
\startformula
\startmatrix[align=left]
\NC \underline{G_{\Pi, A}^{\rm{priv}}(\lambda, b)}: \NR
\NR
\NC (\mpk, \kpol, \msk) \sample \tt{Setup}(\secparam) \NR
\NC (\msg_0, \msg_1, \raccess_0, \raccess_1, \sattr_0, \sattr_1, \alpha) \sample A_1^{O_1, O_2, O_3, \important O_4}(\secparam, \mpk) \NR
\NC \ek_{\sattr_b} \sample \skgen(\msk, \sattr_b) \NR
\NC \cipher \sample \enc(\ek_{\sattr_b}, \raccess_b, \msg_b) \NR
\NC b' \sample A_2^{O_1, O_2, O_3, \important O_4}(\secparam, \cipher, \alpha) \NR
\stopmatrix
\stopformula
\stopslide

\startslide[title={CCA Authenticity Game}]
Captures security against malicious senders.
\startformula
\startmatrix[align=left]
\underline{G_{\Pi, A}^{\rm{auth}}(\lambda)}: \NR
\NR
(\mpk, \kpol, \msk) \sample \tt{Setup}(\secparam) \NR
(\cipher, \rho, \saccess) \sample A_1^{O_1, O_2, O_3, \important O_5}(\secparam, \mpk) \NR
\dk_\rattr \sample \rkgen(\msk, \rattr_b) \NR
\dk_\saccess \sample \polgen(\kpol, \saccess) \NR
m = \dec(\dk_\rattr, \dk_\saccess, \cipher) \NR
\NR
\important{(\cipher \not\in \mathbb{O}_{O_5})} \land \forall \sattr \in \cQuery_{O_1}: (\saccess(\sattr) = 0) \land (\msg \ne \bot) \NR
\stopmatrix
\stopformula
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Dual-policy ABE}
]

\startslide[title={Dual-policy ABE}]
Similar to Arranged Matchmaking
\startitemize[packed]
\item Both the sender and the receiver can specify a policy
\item One private key per user
\item A single decryption key is associated with both the receiver’s policy and attributes
\stopitemize

But
\startitemize[packed]
\item In case of mismatch we know the reason why the match did not occur!
\stopitemize
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={Some formal definitions}
]

\startslide[title={Signatures: a formal definition}]
A signature scheme $\Pi = (\kgen, \sign, \ver)$ satisfies:
\startitemize[n,packed,broad]
\item {\bf Correctness}. $\forall\secpar\in\NN$, $\forall (\sk, \pk) \sample \kgen(\secparam)$, and $\forall \msg \in \cMSG$:
\startformula
P[\ver(\pk, \msg, \sign(\sk, \msg)) = 1] = 1.
\stopformula
\item {\bf EUF-CMA}. $\forall$ PPT $\adversary:$
\startformula
Pr[\Sigeufgame_{\Pi,\adversary}(\secpar) = 1] \leq \negl
\stopformula
where $\Sigeufgame_{\Pi,\adversary}(\secpar)$ is the following game:
\startitemize[packed]
\item $(\sk, \pk) \sample KGen(\secparam)$.
\item $(\msg, \signature) \sample \adversary^{\sign(\sk, \cdot)}(\secparam, \pk)$
\item If $\msg \not\in \cQuery_{\sign}$, and $\ver(\pk,\msg, \signature) = 1$, output $1$, else $0$.
\stopitemize
\stopslide

\startslide[title={NIZK: a formal definition}]
A NIZK proof system $\Pi = (\gen, \prover, \verifier)$ for a relation $R$ satisfies:
\startitemize[n, packed, broad, atmargin]
\item {\bf Completeness}. $\forall y \in L$:
\startformula
Pr[\verifier(\omega, y, \pi)=1: \omega \sample \gen(\secparam), \pi \sample \prover(\omega, y, x)] = 1
\stopformula
\item {\bf Soundness}. $\forall y \not\in L, \forall \prover^*$:
\startformula
Pr[\verifier(\omega, y, \pi)=1: \omega \sample \gen(\secparam), \pi \sample \prover^*(\omega, y)] \in \negl
\stopformula
\item {\bf Zero-Knowledge}. $\exists (Z_0, Z_1)$ s.t. $\forall y \in L:$
\startformula
\{\omega, Z_1(\zeta, y): (\omega, \zeta) \sample Z_0(\secparam)\}
\stopformula
\startformula
\approx_c
\stopformula
\startformula
\{\omega, \prover(\omega, y, x): \omega \sample \gen(\secparam)\}
\stopformula
\stopitemize
\stopslide

\startslide[title={True-Simulation Extractability}]
A NIZK $\Pi$ for a relation $R$ satisfies true-simulation f-extractability for a function $f$ if $\exists$ PPT extractor $K = (K_0,K_1)$ s. t. $\forall \adversary$:
\startformula
Pr
\startmatrix[left={\left[\,},right={\,\right]}]
\NC \ver(\omega, y, \pi) = 1 \;\land \NC \NC (\omega, \zeta, \xi) \sample K_0(\secparam) \;\land \NR
\NC (y, \pi) \not\in\mathcal{O}_O \;\land \NC : \NC (y, \pi) \sample \adversary^{O(\zeta, (\cdot, \cdot))}(\omega) \;\land \NR
\NC \forall x: f(x) = z, (y, x) \not \in R \NC \NC z \sample K_1(\xi, y, \pi) \NR
\stopmatrix
\stopformula
* the oracle $O(\zeta, \cdot, \cdot)$ takes as input a pair $(y, x)$ and returns $Z_1(\zeta, y)$ if $(y, x) \in R$ (and otherwise \bot).
\stopslide

\setvariables[foo][
    set={\setups{foopage}},
    title={CCA-Privacy Proof}
]

\startslide[title={CCA Privacy Proof (1/5)}]
We show a proof by reduction to CPA Privacy. This is how our attacker setups the environment.
\blank[3*big]
\externalfigure[images/cca_reduction/1][maxwidth=\textwidth]
\stopslide

\startslide[title={CCA Privacy Proof (2/5)}]
The encryption keys are enhanced with valid signatures produced by the attacker.
\blank[3*big]
\externalfigure[images/cca_reduction/2][maxwidth=\textwidth]
\stopslide

\startslide[title={CCA Privacy Proof (3/5)}]
Decryption keys remain the same. No need to modify them.
\blank[3*big]
\externalfigure[images/cca_reduction/3][maxwidth=\textwidth]
\stopslide

\startslide[title={CCA Privacy Proof (4/5)}]
The decryption queries are simulated thanks to true-simulation f-extractability of the NIZK.
\blank[3*big]
\externalfigure[images/cca_reduction/4][maxwidth=\textwidth]
\stopslide

\startslide[title={CCA Privacy Proof (5/5)}]
Finally, the challenge is enhanced with a simulated proof. Then the attacker returns the same bit.
\blank[3*big]
\externalfigure[images/cca_reduction/5][maxwidth=\textwidth]
\stopslide
\stoptext
